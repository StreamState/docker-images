swagger: "2.0"
info:
  description: "Streamstate endpoints"
  title: "Streamstate"
  version: "1.0.0"
host: "streamstate-api.endpoints.${PROJECT_ID}.cloud.goog" # "echo-api.endpoints.YOUR-PROJECT-ID.cloud.goog"
# basePath: "/${VERSION_MAJOR}"
schemes:
  - https

#produces:
#  - application/json
x-google-backend:
  name: "streamstate-api.endpoints.${PROJECT_ID}.cloud.goog"
  target: ${CLUSTER_IP} ## add IP here

securityDefinitions:
  firebase:
    authorizationUrl: ""
    flow: "implicit"
    type: "oauth2"
    x-google-issuer: "https://securetoken.google.com/${PROJECT_ID}"
    x-google-jwks_uri: "https://www.googleapis.com/service_accounts/v1/metadata/x509/securetoken@system.gserviceaccount.com"
    x-google-audiences: "${PROJECT_ID}"
  JWT:  
    type: apiKey  
    in: query  
    name: access_token  

security:
  - firebase: []
  - JWT: []




paths:
  "/build/container":
    post:
      consumes:
      - application/json
      operationId: createSparkStreamingJob
      summary: Creates a spark streaming job 
      description: Runs unit tests and linting, starts a spark streaming job
      responses:
        '200':
          description: SuccessResponse
          schema:
            type: string
          examples:
            application/text:
              "success"
        '400':
          description: Error for incorrect request
          schema:
            type: object
            properties: 
              err: 
                type: string
      parameters:
      - required: true
        name: body
        in: body
        schema:
          type: object
          properties:
            pythoncode: 
              type: string
              example: "base 64 encoded python code"
            inputs:
              type: array
              items:
                type: object
                properties:
                  topic: 
                    type: string
                    example: "topic1"
                  schema: # schema of the kafka topic
                    type: object
                    properties:
                      fields:
                        type: array
                        items:
                          type: object
                          properties:
                            name:
                              type: string
                              example: "field1"
                            type:
                              type: string
                              example: "string"   
                          required:
                          - name
                          - type          
                  sample: # samples from kafka topic
                    type: array
                    items:
                      type: object # variable properties.  An example is "field1": "somevalue"
                      properties:
                        field1: # not required, just an example
                          type: string 
                          example: "somevalue"
                      additionalProperties: true
                required:
                - topic
                - schema
                - sample

            assertions: # expected output from spark streaming job for unit testing
              type: array
              items:
                type: object
                properties:
                  field1: # not required, just an example
                    type: string 
                    example: "somevalue"
                additionalProperties: true
            kafka:
              type: object
              properties:
                brokers:
                  type: string
                  example: "broker1,broker2" # comma delineated
              required:
              - brokers
            outputs:
              type: object
              properties:
                mode: 
                  type: string
                  enum: [ "append", "complete", "update"],
                checkpoint_location:
                  type: string
                  example: "/tmp/checkpoint"
                output_name: # This is the output topic.  Should this be the same as the cassandra table and the output_schema name??
                  type: string 
                
              required:
                - mode
                - checkpoint_location
                - output_name
            fileinfo:
              type: object
              properties:
                max_file_age:
                  type: string
                  example: "2d"
              required:
                - max_file_age
            table:
              type: object
              properties:
                primary_keys:
                  type: array
                  items:
                    type: string
                    example: "field1"
                output_schema: # avro schema
                  type: object
                  properties:
                    name: 
                      type: string # TODO THIS IS WRONG! avro schema requires it, and I currently use it to create the cassandra table name in entrypoint.  However I use the CassandraOutputStruct in spark streaming app to call the table, which uses the top level appname
                      example: myappname
                    fields:
                      type: array
                      items:
                        type: object
                        properties:
                          name: 
                            type: string
                            example: "field1"
                          type:
                            type: string
                            example: "string"
                        required:
                          - name
                          - type
                  required:
                    - name
                    - fields
            appname: 
              type: string
              example: mytestapp
          required:
           - pythoncode
           - inputs
           - assertions
           - kafka
           - outputs
           - fileinfo
           - table
           - appname
